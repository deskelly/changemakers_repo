{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "DF-JCDUK-PRD-Changemakers"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/GA_Engagement_Overview_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "The derived column and window components have been added to calculated the unique row index i.e rowNumber()",
				"folder": {
					"name": "GoogleAnalytics"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GA_Engagement_Overview_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "GA_Engagement_Overview_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true,",
						"     partitionBy('hash', 1)) ~> SourceProcessFiles",
						"SourceProcessFiles derive(order_id = 1) ~> derivedColumn1",
						"derivedColumn1 window(over(order_id),",
						"     asc(order_id, true),",
						"     id = rowNumber()) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     preSQLs:['drop table if exists Temp_Raw_GA_Engagement_Overview','CREATE TABLE Temp_Raw_GA_Engagement_Overview(\\n     Column_1 varchar(80) null\\n     , Column_2 varchar(80) null\\n     , Column_3 varchar(80) null\\n     , Column_4 varchar(80) null\\n    , id int not null\\n)'],",
						"     postSQLs:['with getColNo as (\\n    select top 1\\n        id\\n    from Temp_Raw_GA_Engagement_Overview\\n    where trim(Column_2) = \\'Views\\'\\n    and trim(Column_1) = \\'Nth day\\'    \\n)\\n, date_extract as (\\n    select top 1\\n        cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 2)), 8) as date) as start_date\\n        , cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 1)), 8) as date) as end_date\\n        , b.id as select_id\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join getColNo b\\n)\\n, date_range as ( \\n    select \\n        start_date\\n        , end_date\\n        , datediff(day, start_date, end_date) as no_days\\n        , select_id\\n    from date_extract\\n)\\n, final_table as (\\n    select\\n    cast(dateadd(day, cast(a.Column_1 as int), b.start_date) as date) as date\\n    , cast(trim(a.Column_2) as float) as val\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join date_range b\\n    where a.id between (b.select_id + 1) and (b.no_days + (b.select_id + 1))\\n)\\n\\n--select * from final_table   \\n\\nMERGE INTO Changemakers_Combined_Overview a\\nUSING final_table b\\n    ON a.channel = \\'Website\\' \\n    and a.sub_channel = \\'Digital Changemakers Hub\\'\\n    and a.date = b.date \\nWHEN MATCHED THEN\\n  UPDATE SET a.impression_by_date = b.val\\n\\nWHEN NOT MATCHED THEN\\n  INSERT (channel, sub_channel, date, timestamp, month, week, impression_by_date)\\n  VALUES (\\n        \\'Website\\'\\n        , \\'Digital Changemakers Hub\\'\\n        , b.date \\n        , b.date\\n        , cast(format(b.date, \\'yyyyMM\\') as int)\\n        , cast(concat(left(b.date,4),  right(datepart(ww, b.date) + 100, 2)) as int)\\n        , b.val\\n        );','with getColNo as (\\n    select top 1\\n        id\\n    from Temp_Raw_GA_Engagement_Overview\\n    where trim(Column_2) = \\'Event count\\'\\n    and trim(Column_1) = \\'Nth day\\'\\n)\\n, date_extract as (\\n    select top 1\\n        cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 2)), 8) as date) as start_date\\n        , cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 1)), 8) as date) as end_date\\n        , b.id as select_id\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join getColNo b\\n)\\n, date_range as ( \\n    select \\n        start_date\\n        , end_date\\n        , datediff(day, start_date, end_date) as no_days\\n        , select_id\\n    from date_extract\\n)\\n, final_table as (\\n    select \\n        cast(dateadd(day, cast(a.Column_1 as int), b.start_date) as date) as date\\n        , cast(a.Column_2 as float) as val\\n        -- , b.select_id\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join date_range b\\n    where a.id between (b.select_id + 1) and (b.no_days + (b.select_id + 1))\\n)\\nMERGE INTO Changemakers_Combined_Overview a\\nUSING final_table b\\n    ON a.channel = \\'Website\\' \\n    and a.sub_channel = \\'Digital Changemakers Hub\\'\\n    and a.date = b.date \\nWHEN MATCHED THEN\\n  UPDATE SET a.click_through_rate = b.val\\n\\nWHEN NOT MATCHED THEN\\n  INSERT (channel, sub_channel, date, timestamp, month, week, click_through_rate)\\n  VALUES (\\n        \\'Website\\'\\n        , \\'Digital Changemakers Hub\\'\\n        , b.date \\n        , b.date\\n        , cast(format(b.date, \\'yyyyMM\\') as int)\\n        , cast(concat(left(b.date,4),  right(datepart(ww, b.date) + 100, 2)) as int)\\n        , b.val\\n        );','with getColNo as (\\n    select top 1\\n        id\\n    from Temp_Raw_GA_Engagement_Overview\\n    where trim(Column_2) = \\'Average engagement time\\'\\n    and trim(Column_1) = \\'Nth day\\'\\n)\\n, date_extract as (\\n    select top 1\\n        cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 2)), 8) as date) as start_date\\n        , cast(right((select Column_1 from Temp_Raw_GA_Engagement_Overview where id = (b.id - 1)), 8) as date) as end_date\\n        , b.id as select_id\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join getColNo b\\n)\\n, date_range as ( \\n    select \\n        start_date\\n        , end_date\\n        , datediff(day, start_date, end_date) as no_days\\n        , select_id\\n    from date_extract\\n)\\n, final_table as (\\n    select \\n        cast(dateadd(day, cast(a.Column_1 as int), b.start_date) as date) as date\\n        , cast(a.Column_2 as float) as val\\n        -- , b.select_id\\n    from Temp_Raw_GA_Engagement_Overview a\\n    cross join date_range b\\n    where a.id between (b.select_id + 1) and (b.no_days + (b.select_id + 1))\\n)\\n--select * from final_table\\n\\nMERGE INTO Changemakers_Combined_Overview a\\nUSING final_table b\\n    ON a.channel = \\'Website\\' \\n    and a.sub_channel = \\'Digital Changemakers Hub\\'\\n    and a.date = b.date \\nWHEN MATCHED THEN\\n  UPDATE SET a.time_spent_on_site_page_podcast_vodcast = b.val\\n\\nWHEN NOT MATCHED THEN\\n  INSERT (channel, sub_channel, date, timestamp, month, week, time_spent_on_site_page_podcast_vodcast)\\n  VALUES (\\n        \\'Website\\'\\n        , \\'Digital Changemakers Hub\\'\\n        , b.date \\n        , b.date\\n        , cast(format(b.date, \\'yyyyMM\\') as int)\\n        , cast(concat(left(b.date,4),  right(datepart(ww, b.date) + 100, 2)) as int)\\n        , b.val\\n  );','drop table if exists Temp_Raw_GA_Engagement_Overview'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Column_1,",
						"          Column_2,",
						"          Column_3,",
						"          Column_4,",
						"          id",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/GA_Snapshot_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "The derived column and window components have been added to calculated the unique row index i.e rowNumber()",
				"folder": {
					"name": "GoogleAnalytics"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "GA_Snapshot_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "GA_Snapshot_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string,",
						"          Column_6 as string,",
						"          Column_7 as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true,",
						"     partitionBy('hash', 1)) ~> SourceProcessFiles",
						"SourceProcessFiles derive(order_id = 1) ~> derivedColumn1",
						"derivedColumn1 window(over(order_id),",
						"     asc(order_id, true),",
						"     id = rowNumber()) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     preSQLs:['drop table if exists Temp_Raw_GA_Snapshot','CREATE TABLE Temp_Raw_GA_Snapshot(\\n     Column_1 varchar(80) null\\n     , Column_2 varchar(80) null\\n     , Column_3 varchar(80) null\\n     , Column_4 varchar(80) null\\n     , Column_5 varchar(80) null\\n     , Column_6 varchar(80) null\\n     , Column_7 varchar(80) null\\n    , id int not null\\n)'],",
						"     postSQLs:['with getColNo as (\\n    select top 1\\n        id\\n    from Temp_Raw_GA_Snapshot\\n    where trim(Column_2) = \\'New users\\'\\n    and trim(Column_1) = \\'Nth day\\'    \\n)\\n, date_extract as (\\n    select top 1\\n        cast(right((select Column_1 from Temp_Raw_GA_Snapshot where id = (b.id - 2)), 8) as date) as start_date\\n        , cast(right((select Column_1 from Temp_Raw_GA_Snapshot where id = (b.id - 1)), 8) as date) as end_date\\n        , b.id as select_id\\n    from Temp_Raw_GA_Snapshot a\\n    cross join getColNo b\\n)\\n, date_range as ( \\n    select \\n        start_date\\n        , end_date\\n        , datediff(day, start_date, end_date) as no_days\\n        , select_id\\n    from date_extract\\n)\\n, final_table as (\\n    select\\n    cast(dateadd(day, cast(a.Column_1 as int), b.start_date) as date) as date\\n    , cast(trim(a.Column_2) as float) as val\\n    from Temp_Raw_GA_Snapshot a\\n    cross join date_range b\\n    where a.id between (b.select_id + 1) and (b.no_days + (b.select_id + 1))\\n)\\n\\n--select * from final_table   \\n\\nMERGE INTO Changemakers_Combined_Overview a\\nUSING final_table b\\n    ON a.channel = \\'Website\\' \\n    and a.sub_channel = \\'Digital Changemakers Hub\\'\\n    and a.date = b.date \\nWHEN MATCHED THEN\\n  UPDATE SET a.users_by_date = b.val\\n\\nWHEN NOT MATCHED THEN\\n  INSERT (channel,sub_channel,date,timestamp,month,week,users_by_date)\\n  VALUES (\\n        \\'Website\\'\\n        , \\'Digital Changemakers Hub\\'\\n        , b.date \\n        , b.date\\n        , cast(format(b.date, \\'yyyyMM\\') as int)\\n        , cast(concat(left(b.date,4),  right(datepart(ww, b.date) + 100, 2)) as int)\\n        , b.val\\n        );','drop table if exists Temp_Raw_GA_Snapshot'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Column_1,",
						"          Column_2,",
						"          Column_3,",
						"          Column_4,",
						"          id",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedinCampaign_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Linkedin"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "LinkedinCampaign_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "LinkedinCampaign_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          {Start Date (in UTC)} as string,",
						"          {Account Name} as string,",
						"          Currency as string,",
						"          {Campaign Group ID} as string,",
						"          {Campaign Group Name} as string,",
						"          {Campaign Group Status} as string,",
						"          {Campaign Group Start Date} as string,",
						"          {Campaign Group End Date} as string,",
						"          {Campaign Group Total Budget} as string,",
						"          {Campaign ID} as string,",
						"          {Campaign Name} as string,",
						"          {Campaign Objective} as string,",
						"          {Campaign Type} as string,",
						"          {Campaign Status} as string,",
						"          {Cost Type} as string,",
						"          {Total Budget} as string,",
						"          {Campaign Start Date} as string,",
						"          {Campaign End Date} as string,",
						"          {Total Spent} as string,",
						"          Impressions as string,",
						"          Clicks as string,",
						"          {Click Through Rate} as string,",
						"          {Average CPM} as string,",
						"          {Average CPC} as string,",
						"          Reactions as string,",
						"          Comments as string,",
						"          Shares as string,",
						"          Follows as string,",
						"          {Other Clicks} as string,",
						"          {Total Social Actions} as string,",
						"          {Total Engagements} as string,",
						"          {Engagement Rate} as string,",
						"          {Viral Impressions} as string,",
						"          {Viral Clicks} as string,",
						"          {Viral Reactions} as string,",
						"          {Viral Comments} as string,",
						"          {Viral Shares} as string,",
						"          {Viral Follows} as string,",
						"          {Viral Other Clicks} as string,",
						"          Conversions as string,",
						"          {Post-Click Conversions} as string,",
						"          {View-Through Conversions} as string,",
						"          {Conversion Rate} as string,",
						"          {Cost per Conversion} as string,",
						"          {Total Conversion Value} as string,",
						"          {Return on Ad Spend} as string,",
						"          {Viral Conversions} as string,",
						"          {Viral Post-Click Conversions} as string,",
						"          {Viral View-Through Conversions} as string,",
						"          Leads as string,",
						"          {Lead Forms Opened} as string,",
						"          {Lead Form Completion Rate} as string,",
						"          {Cost per Lead} as string,",
						"          {Video Plays} as string,",
						"          {Video Views} as string,",
						"          {Video View Rate} as string,",
						"          {Video Views at 25%} as string,",
						"          {Video Views at 50%} as string,",
						"          {Video Views at 75%} as string,",
						"          {Video Completions} as string,",
						"          {Video Completion Rate} as string,",
						"          {Full Screen Plays} as string,",
						"          eCPV as string,",
						"          {Viral Video Plays} as string,",
						"          {Viral Video Views} as string,",
						"          {Viral Video Views at 25%} as string,",
						"          {Viral Video Views at 50%} as string,",
						"          {Viral Video Views at 75%} as string,",
						"          {Viral Video Completions} as string,",
						"          {Viral Video Completion Rate} as string,",
						"          {Viral Video Full Screen Plays} as string,",
						"          {Event Registrations} as string,",
						"          {Click Event Registrations} as string,",
						"          {View Event Registrations} as string,",
						"          {Viral Event Registrations} as string,",
						"          {Viral Click Event Registrations} as string,",
						"          {Viral View Event Registrations} as string,",
						"          {Average Daily Spend} as string,",
						"          {Clicks to Landing Page} as string,",
						"          {Clicks to LinkedIn Page} as string,",
						"          {Leads (Work Email)} as string,",
						"          {Lead Form Completion Rate (Work Email)} as string,",
						"          {Cost Per Lead (Work Email)} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          each(match(/* All input columns */true()),",
						"               /* Input name */$$ = $$)",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedinContentAllPosts_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Linkedin"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "LinkedinContentAllPosts_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles",
							"description": "Import data from LinkedinContentAllPosts_GetFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "LinkedinContentAllPosts_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          {Post title} as string,",
						"          {Post link} as string,",
						"          {Post type} as string,",
						"          {Campaign name} as string,",
						"          {Posted by} as string,",
						"          {Created date} as date 'MM/dd/yyyy',",
						"          {Campaign start date} as date 'MM/dd/yyyy',",
						"          {Campaign end date} as date 'MM/dd/yyyy',",
						"          Audience as string,",
						"          Impressions as integer,",
						"          {Views (Excluding offsite video views)} as integer,",
						"          {Offsite Views} as integer,",
						"          Clicks as integer,",
						"          {Click through rate (CTR)} as double,",
						"          Likes as integer,",
						"          Comments as integer,",
						"          Reposts as integer,",
						"          Follows as integer,",
						"          {Engagement rate} as double,",
						"          {Content Type} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['delete from Temp_Raw_LinkedinContentAllPosts where post_title is null','with exist_check as (\\n  select distinct post_title \\n  from Raw_LinkedinContentAllPosts\\n)\\ninsert into Raw_LinkedinContentAllPosts\\n    select \\n      a.created_date as date\\n      , a.post_title\\n      , a.post_link\\n      , a.post_type\\n      , a.campaign_name\\n      , a.posted_by\\n      , a.created_date\\n      , a.campaign_start_date\\n      , a.campaign_end_date\\n      , a.audience\\n      , a.impressions\\n      , a.views\\n      , a.offsite_views\\n      , a.clicks\\n      , a.click_through_rate\\n      , a.likes\\n      , a.comments\\n      , a.reposts\\n      , a.follows\\n      , a.engagement_rate\\n      , a.content_type\\n    from Temp_Raw_LinkedinContentAllPosts a\\n    left outer join exist_check b on a.post_title = b.post_title \\n    where b.post_title is null','with raw_data as (\\n    select \\n        post_title\\n        ,sum(impressions) as impressions\\n        ,sum(views) as views\\n        ,sum(offsite_views) as offsite_views\\n        ,sum(clicks) as clicks\\n        ,sum(click_through_rate) as click_through_rate\\n        ,sum(likes) as likes\\n        ,sum(comments) as comments\\n        ,sum(reposts) as reposts\\n        ,sum(follows) as follows\\n        ,sum(engagement_rate) as engagement_rate\\n    from Raw_LinkedinContentAllPosts\\n    group by post_title\\n)\\ninsert into Raw_LinkedinContentAllPosts\\n    select\\n      cast(getdate() as date) as date \\n      , trg.post_title\\n      , trg.post_link\\n      , trg.post_type\\n      , trg.campaign_name\\n      , trg.posted_by\\n      , trg.created_date\\n      , trg.campaign_start_date\\n      , trg.campaign_end_date\\n      , trg.audience\\n      , case when rg.impressions is null then trg.impressions else (trg.impressions - rg.impressions) end as impressions\\n      , case when rg.views is null then trg.views else (trg.views - rg.views) end as views\\n      , case when rg.offsite_views is null then trg.offsite_views else (trg.offsite_views - rg.offsite_views) end as offsite_views\\n      , case when rg.clicks is null then trg.clicks else (trg.clicks - rg.clicks) end as clicks\\n      , case when rg.click_through_rate is null then trg.click_through_rate else (trg.click_through_rate - rg.click_through_rate) end as click_through_rate\\n      , case when rg.likes is null then trg.likes else (trg.likes - rg.likes) end as likes\\n      , case when rg.comments is null then trg.comments else (trg.comments - rg.comments) end as comments\\n      , case when rg.reposts is null then trg.reposts else (trg.reposts - rg.reposts) end as reposts\\n      , case when rg.follows is null then trg.follows else (trg.follows - rg.follows) end as follows\\n      , case when rg.engagement_rate is null then trg.engagement_rate else (trg.engagement_rate - rg.engagement_rate) end as engagement_rate\\n      , trg.content_type\\n    from Temp_Raw_LinkedinContentAllPosts trg\\n    left outer join raw_data rg\\n    on trg.post_title = rg.post_title\\n    where trg.impressions - rg.impressions > 0','delete from Changemakers_Combined_Overview where sub_channel = \\'Linkedin Organic\\' and activity_calendar_events is not null','insert into Changemakers_Combined_Overview (channel,sub_channel,date,timestamp,month,week,activity_calendar_events,event_occurence_by_date,event_occurence_by_time,activity_implemented_by,conversion_listened_watched,listened_watched_full_podcast_episode)\\nselect\\n    \\'Social Media\\' as \\'channel\\'\\n    ,\\'Linkedin Organic\\' as \\'sub_channel\\'\\n    , date \\n    , date as timestamp\\n    , cast(format(date, \\'yyyyMM\\') as int) as month\\n    , cast(concat(left(date,4),  right(datepart(ww, date) + 100, 2)) as int) as week\\n    , post_title as activity_calendar_events\\n    , created_date as event_occurence_by_date\\n    , case when campaign_start_date is null then created_date end as event_occurence_by_time\\n    , posted_by as activity_implemented_by\\n    , clicks as conversion_listened_watched\\n    , clicks as listened_watched_full_podcast_episode\\nfrom Raw_LinkedinContentAllPosts','drop table if exists Temp_Raw_LinkedinContentAllPosts'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          post_title = {Post title},",
						"          post_link = {Post link},",
						"          post_type = {Post type},",
						"          campaign_name = {Campaign name},",
						"          posted_by = {Posted by},",
						"          created_date = {Created date},",
						"          campaign_start_date = {Campaign start date},",
						"          campaign_end_date = {Campaign end date},",
						"          audience = Audience,",
						"          impressions = Impressions,",
						"          views = {Views (Excluding offsite video views)},",
						"          offsite_views = {Offsite Views},",
						"          clicks = Clicks,",
						"          click_through_rate = {Click through rate (CTR)},",
						"          likes = Likes,",
						"          comments = Comments,",
						"          reposts = Reposts,",
						"          follows = Follows,",
						"          engagement_rate = {Engagement rate},",
						"          content_type = {Content Type}",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedinContentMetrics_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Linkedin"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "LinkedinContentMetrics_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles",
							"description": "Import data from LinkedinContentMetrics_GetFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "LinkedinContentMetrics_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Date as date 'MM/dd/yyyy',",
						"          {Impressions (organic)} as integer,",
						"          {Impressions (sponsored)} as integer,",
						"          {Impressions (total)} as integer,",
						"          {Unique impressions (organic)} as integer,",
						"          {Clicks (organic)} as integer,",
						"          {Clicks (sponsored)} as integer,",
						"          {Clicks (total)} as integer,",
						"          {Reactions (organic)} as integer,",
						"          {Reactions (sponsored)} as integer,",
						"          {Reactions (total)} as integer,",
						"          {Comments (organic)} as integer,",
						"          {Comments (sponsored)} as integer,",
						"          {Comments (total)} as integer,",
						"          {Reposts (organic)} as integer,",
						"          {Reposts (sponsored)} as integer,",
						"          {Reposts (total)} as integer,",
						"          {Engagement rate (organic)} as double '0',",
						"          {Engagement rate (sponsored)} as double '0',",
						"          {Engagement rate (total)} as double",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['delete from Raw_LinkedinContent where \\ndate in (select distinct date from Temp_Raw_LinkedinContent where date is not null)','insert Raw_LinkedinContent\\nselect * from Temp_Raw_LinkedinContent','delete from Changemakers_Combined_Overview where sub_channel = \\'Linkedin Organic\\' and date >= (select cast(dateadd(day, -35, max(date)) as date) from Temp_Raw_LinkedinContent)','insert into Changemakers_Combined_Overview (channel,sub_channel,date,timestamp,month,week,impression_by_date, users_by_date,likes_consid_engage_by_date, shares_by_date,comments_by_date,total_engagements,conversion_total_clicks,click_through_rate)\\nselect\\n    \\'Social Media\\' as \\'channel\\'\\n    ,\\'Linkedin Organic\\' as \\'sub_channel\\'\\n    , rlc.date \\n    , rlc.date as timestamp\\n    , cast(format(rlc.date, \\'yyyyMM\\') as int) as month\\n    , cast(concat(left(rlc.date,4),  right(datepart(ww, rlc.date) + 100, 2)) as int) as week\\n    , rlc.impressions_total as impression_by_date\\n    , rlc.impressions_total as users_by_date\\n    , rlc.reactions_total as likes_consid_engage_by_date\\n    , rlc.reposts_total as shares_by_date\\n    , rlc.comments_total as comments_by_date\\n    , (rlc.reactions_total + rlc.reposts_total + rlc.comments_total + rlc.clicks_total) as total_engagements\\n    , rlc.clicks_total as conversion_total_clicks\\n    , case when rlc.impressions_total = 0 then 0 else (cast(rlc.clicks_total as decimal) / cast(rlc.impressions_total as decimal) * 100) end as click_through_rate  \\nfrom Raw_LinkedinContent rlc\\nleft outer join Raw_LinkedinVisitors rlv on rlc.date = rlv.date\\nwhere rlc.date >= (select cast(dateadd(day, -35, max(date)) as date) from Temp_Raw_LinkedinContent) ','drop table if exists Temp_Raw_LinkedinContent'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          date = Date,",
						"          impressions_organic = {Impressions (organic)},",
						"          impressions_sponsored = {Impressions (sponsored)},",
						"          impressions_total = {Impressions (total)},",
						"          unique_impressions_organic = {Unique impressions (organic)},",
						"          clicks_organic = {Clicks (organic)},",
						"          clicks_ssponsored = {Clicks (sponsored)},",
						"          clicks_total = {Clicks (total)},",
						"          reactions_organic = {Reactions (organic)},",
						"          reactions_sponsored = {Reactions (sponsored)},",
						"          reactions_total = {Reactions (total)},",
						"          comments_organic = {Comments (organic)},",
						"          comments_sponsored = {Comments (sponsored)},",
						"          comments_total = {Comments (total)},",
						"          reposts_organic = {Reposts (organic)},",
						"          reposts_sponsored = {Reposts (sponsored)},",
						"          reposts_total = {Reposts (total)},",
						"          engagement_rate_organic = {Engagement rate (organic)},",
						"          engagement_rate_sponsored = {Engagement rate (sponsored)},",
						"          engagement_rate_total = {Engagement rate (total)}",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedinFollowers_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Linkedin"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "LinkedinFollowers_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "LinkedinFollowers_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Date as date 'MM/dd/yyyy',",
						"          {Sponsored followers} as integer,",
						"          {Organic followers} as integer,",
						"          {Total followers} as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['delete from Raw_LinkedinFollowers where \\ndate in (select distinct date from Temp_Raw_LinkedinFollowers where date is not null)','insert into Raw_LinkedinFollowers\\nselect * from Temp_Raw_LinkedinFollowers','drop table if exists Temp_Raw_LinkedinFollowers'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          date = Date,",
						"          sponsored_followers = {Sponsored followers},",
						"          organic_followers = {Organic followers},",
						"          total_followers = {Total followers}",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LinkedinVisitors_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Linkedin"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "LinkedinVisitors_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "LinkedinVisitors_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Date as date 'MM/dd/yyyy',",
						"          {Overview page views (desktop)} as integer,",
						"          {Overview page views (mobile)} as integer,",
						"          {Overview page views (total)} as integer,",
						"          {Overview unique visitors (desktop)} as integer,",
						"          {Overview unique visitors (mobile)} as integer,",
						"          {Overview unique visitors (total)} as integer,",
						"          {Life page views (desktop)} as integer,",
						"          {Life page views (mobile)} as integer,",
						"          {Life page views (total)} as integer,",
						"          {Life unique visitors (desktop)} as integer,",
						"          {Life unique visitors (mobile)} as integer,",
						"          {Life unique visitors (total)} as integer,",
						"          {Jobs page views (desktop)} as integer,",
						"          {Jobs page views (mobile)} as integer,",
						"          {Jobs page views (total)} as integer,",
						"          {Jobs unique visitors (desktop)} as integer,",
						"          {Jobs unique visitors (mobile)} as integer,",
						"          {Jobs unique visitors (total)} as integer,",
						"          {Total page views (desktop)} as integer,",
						"          {Total page views (mobile)} as integer,",
						"          {Total page views (total)} as integer,",
						"          {Total unique visitors (desktop)} as integer,",
						"          {Total unique visitors (mobile)} as integer,",
						"          {Total unique visitors (total)} as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['delete from Raw_LinkedinVisitors where \\ndate in (select distinct date from Temp_Raw_LinkedinVisitors where date is not null)','insert into Raw_LinkedinVisitors\\nselect * from Temp_Raw_LinkedinVisitors where date is not null','drop table if exists Temp_Raw_LinkedinVisitors'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          date = Date,",
						"          overview_page_views_desktop = {Overview page views (desktop)},",
						"          overview_page_views_mobile = {Overview page views (mobile)},",
						"          overview_page_views_total = {Overview page views (total)},",
						"          overview_unique_visitors_desktop = {Overview unique visitors (desktop)},",
						"          overview_unique_visitors_mobile = {Overview unique visitors (mobile)},",
						"          overview_unique_visitors_total = {Overview unique visitors (total)},",
						"          life_page_views_desktop = {Life page views (desktop)},",
						"          life_page_views_mobile = {Life page views (mobile)},",
						"          life_page_views_total = {Life page views (total)},",
						"          life_unique_visitors_desktop = {Life unique visitors (desktop)},",
						"          life_unique_visitors_mobile = {Life unique visitors (mobile)},",
						"          life_unique_visitors_total = {Life unique visitors (total)},",
						"          jobs_page_views_desktop = {Jobs page views (desktop)},",
						"          jobs_page_views_mobile = {Jobs page views (mobile)},",
						"          jobs_page_views_total = {Jobs page views (total)},",
						"          {jobs_unique_ visitors_desktop} = {Jobs unique visitors (desktop)},",
						"          jobs_unique_visitors_mobile = {Jobs unique visitors (mobile)},",
						"          jobs_unique_visitors_total = {Jobs unique visitors (total)},",
						"          total_page_views_desktop = {Total page views (desktop)},",
						"          total_page_views_mobile = {Total page views (mobile)},",
						"          total_page_views_total = {Total page views (total)},",
						"          total_unique_visitors_desktop = {Total unique visitors (desktop)},",
						"          total_unique_visitors_mobile = {Total unique visitors (mobile)},",
						"          total_unique_visitors_total = {Total unique visitors (total)}",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Twitter_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Twitter"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Twitter_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Twitter_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Date as date 'yyyy-MM-dd',",
						"          {Tweets published} as integer '000',",
						"          impressions as integer '000',",
						"          engagements as integer '000',",
						"          {engagement rate} as double '###,###,000.###',",
						"          retweets as integer '000',",
						"          replies as integer '000',",
						"          likes as integer '000',",
						"          {user profile clicks} as integer '000',",
						"          {url clicks} as integer '0',",
						"          {hashtag clicks} as integer '0',",
						"          {detail expands} as integer '0',",
						"          {permalink clicks} as integer '0',",
						"          {app opens} as integer '0',",
						"          {app installs} as integer '0',",
						"          follows as integer '0',",
						"          {email tweet} as integer '000',",
						"          {dial phone} as integer '000',",
						"          {media views} as integer '000',",
						"          {media engagements} as integer '000',",
						"          {promoted impressions} as integer '000',",
						"          {promoted engagements} as integer '000',",
						"          {promoted engagement rate} as integer '000',",
						"          {promoted retweets} as integer '000',",
						"          {promoted replies} as integer '000',",
						"          {promoted likes} as integer '000',",
						"          {promoted user profile clicks} as integer '000',",
						"          {promoted url clicks} as integer '000',",
						"          {promoted hashtag clicks} as integer '000',",
						"          {promoted detail expands} as integer '000',",
						"          {promoted permalink clicks} as integer '000',",
						"          {promoted app opens} as integer '000',",
						"          {promoted app installs} as integer '000',",
						"          {promoted follows} as integer '000',",
						"          {promoted email tweet} as integer '000',",
						"          {promoted dial phone} as integer '000',",
						"          {promoted media views} as integer '000',",
						"          {promoted media engagements} as integer '000'",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['delete from Raw_Twitter where \\ndate in (select distinct date from Temp_Raw_Twitter where date is not null)','insert Raw_Twitter\\nselect * from Temp_Raw_Twitter','delete from Changemakers_Combined_Overview where sub_channel = \\'Twitter\\'','insert into Changemakers_Combined_Overview (channel,sub_channel,date,timestamp,month,week, impression_by_date, users_by_date, activity_calendar_events, event_occurence_by_date, event_occurence_by_time, activity_implemented_by, likes_consid_engage_by_date, shares_by_date, comments_by_date, follows_by_date, total_engagements, conversion_total_clicks, click_through_rate, conversion_listened_watched, listened_watched_full_podcast_episode, video_view_rate, video_completion_rate )\\n  select\\n    \\'Social Media\\' as \\'channel\\'\\n    ,\\'Twitter\\' as \\'sub_channel\\'\\n    , date \\n    , date as timestamp\\n    , cast(format(date, \\'yyyyMM\\') as int) as month\\n    , cast(concat(left(date,4),  right(datepart(ww, date) + 100, 2)) as int) as week\\n    , impressions as impression_by_date\\n    , impressions as users_by_date\\n    , tweets_published as activity_calendar_events\\n    , date as event_occurence_by_date\\n    , date as event_occurence_by_time\\n    , \\'Janet Guest\\' as activity_implemented_by\\n    , likes as likes_consid_engage_by_date\\n    , retweets as shares_by_date\\n    , replies as comments_by_date\\n    , follows as follows_by_date\\n    , (likes + retweets + replies + follows + user_profile_clicks + url_clicks + hashtag_clicks)  as total_engagements\\n    , (user_profile_clicks + url_clicks + hashtag_clicks + detail_expands + permalink_clicks + app_opens + app_installs) as conversion_total_clicks\\n    , case when impressions = 0 then 0 else cast((user_profile_clicks + url_clicks + hashtag_clicks + detail_expands + permalink_clicks + app_opens + app_installs) as decimal) / cast(impressions as decimal) * 100 end as click_through_rate\\n    , media_views as conversion_listened_watched\\n    , media_views as listened_watched_full_podcast_episode\\n    , case when impressions = 0 then 0 else (cast(media_views as decimal) / cast(impressions as decimal) * 100) end as video_view_rate\\n    , case when impressions = 0 then 0 else (cast(media_views as decimal) / cast(impressions as decimal) * 100) end as video_completion_rate\\nfrom Raw_Twitter','drop table if exists Temp_Raw_Twitter'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          date = Date,",
						"          tweets_published = {Tweets published},",
						"          impressions,",
						"          engagements,",
						"          engagement_rate = {engagement rate},",
						"          retweets,",
						"          replies,",
						"          likes,",
						"          user_profile_clicks = {user profile clicks},",
						"          url_clicks = {url clicks},",
						"          hashtag_clicks = {hashtag clicks},",
						"          detail_expands = {detail expands},",
						"          permalink_clicks = {permalink clicks},",
						"          app_opens = {app opens},",
						"          app_installs = {app installs},",
						"          follows,",
						"          email_tweet = {email tweet},",
						"          dial_phone = {dial phone},",
						"          media_views = {media views},",
						"          media_engagements = {media engagements}",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Umbraco_LikesLogReports_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Umbraco"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Umbraco_LikesLogReports_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Umbraco_LikesLogReports_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          ContentId as string,",
						"          ContentName as string,",
						"          DateSubmitted as string,",
						"          DownVotes as string,",
						"          Votes as string,",
						"          Name as string,",
						"          Email as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          ContentId,",
						"          ContentName,",
						"          DateSubmitted,",
						"          DownVotes,",
						"          Votes,",
						"          Name,",
						"          Email",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Umbraco_MediaLogReports_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Umbraco"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Umbraco_LikesLogReports_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Umbraco_LikesLogReports_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          ContentId as string,",
						"          ContentName as string,",
						"          DateSubmitted as string,",
						"          DownVotes as string,",
						"          Votes as string,",
						"          Name as string,",
						"          Email as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          ContentId,",
						"          ContentName,",
						"          DateSubmitted,",
						"          DownVotes,",
						"          Votes,",
						"          Name,",
						"          Email",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Vimeo_DataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Vimeo"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Vimeo_GetFiles",
								"type": "DatasetReference"
							},
							"name": "SourceProcessFiles"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Vimeo_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          plays as integer,",
						"          loads as integer,",
						"          downloads as integer,",
						"          finishes as integer,",
						"          likes as integer,",
						"          comments as integer,",
						"          uri as string,",
						"          name as string,",
						"          created_time as string,",
						"          sizes as string,",
						"          unique_viewers as integer,",
						"          mean_percent as integer,",
						"          sum_seconds as integer,",
						"          mean_seconds as integer,",
						"          unique_loads as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: true,",
						"     purgeFiles: true) ~> SourceProcessFiles",
						"SourceProcessFiles derive(created_time = toTimestamp(created_time, \"yyyy-MM-dd'T'HH:mm:ss\")) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     recreate:true,",
						"     format: 'table',",
						"     postSQLs:['insert into Raw_Vimeo\\n    select \\n        CAST(GETDATE() AS DATE) as date\\n        ,a.plays\\n        ,a.loads\\n        ,a.downloads\\n        ,a.finishes\\n        ,a.likes\\n        ,a.comments\\n        ,a.uri\\n        ,a.name\\n        ,a.created_time\\n        ,a.sizes\\n        ,a.unique_viewers\\n        ,a.mean_percent\\n        ,a.sum_seconds\\n        ,a.mean_seconds\\n        ,a.unique_loads\\n    from Temp_Raw_Vimeo a\\n    left outer join Raw_Vimeo b on a.uri = b.uri\\n    where a.uri is not null \\n    and b.uri is null','with raw_data as (\\n    SELECT \\n        uri\\n        ,sum(plays) as plays\\n        ,sum(loads) as loads\\n        ,sum(downloads) as downloads\\n        ,sum(finishes) as finishes\\n        ,sum(likes) as likes\\n        ,sum(comments) as comments\\n        ,sum(unique_viewers) as unique_viewers\\n        ,sum(mean_percent) as mean_percent\\n        ,sum(sum_seconds) as sum_seconds\\n        ,sum(mean_seconds) as mean_seconds\\n        ,sum(unique_loads) as unique_loads\\n    FROM Raw_Vimeo\\n    group by uri \\n)\\ninsert into Raw_Vimeo\\n    SELECT \\n        CAST(GETDATE() AS DATE) as date\\n        ,case when r.plays is null then t.plays else (t.plays - r.plays) end as plays  \\n        ,case when t.loads is null then t.loads else (t.loads - r.loads) end as loads\\n        ,case when t.downloads is null then t.downloads else (t.downloads - r.downloads) end as downloads\\n        ,case when t.finishes is null then t.finishes else (t.finishes - r.finishes) end as finishes\\n        ,case when t.likes is null then t.likes else (t.likes - r.likes) end as likes\\n        ,case when t.comments is null then t.comments else (t.comments - r.comments) end as comments\\n        ,t.uri\\n        ,t.name\\n        ,t.created_time\\n        ,t.sizes\\n        ,case when t.unique_viewers is null then t.unique_viewers else (t.unique_viewers - r.unique_viewers) end as unique_viewers\\n        ,case when t.mean_percent is null then t.mean_percent else (t.mean_percent - r.mean_percent) end as mean_percent\\n        ,case when t.sum_seconds is null then t.sum_seconds else (t.sum_seconds - r.sum_seconds) end as sum_seconds\\n        ,case when t.mean_seconds is null then t.mean_seconds else (t.mean_seconds - r.mean_seconds) end as mean_seconds\\n        ,case when t.unique_loads is null then t.unique_loads else (t.unique_loads - r.unique_loads) end as unique_loads\\n    FROM Temp_Raw_Vimeo t\\n    inner join raw_data r on t.uri = r.uri\\n    where t.unique_viewers != r.unique_viewers','delete from Changemakers_Combined_Overview where sub_channel = \\'Vimeo\\';','insert into Changemakers_Combined_Overview (channel, sub_channel, date, timestamp, month, week, impression_by_date, users_by_date, activity_calendar_events, event_occurence_by_date, event_occurence_by_time, activity_implemented_by, likes_consid_engage_by_date, downloads_by_date, total_engagements, engagement_rate_by_activity_1, engagement_rate_by_activity_2, conversion_listened_watched, listened_watched_full_podcast_episode, video_view_rate, video_completion_rate) \\n    select\\n        \\'Podcast/Vodcast\\' as channel\\n        ,\\'Vimeo\\' as sub_channel\\n        , date \\n        , date as timestamp\\n        , cast(format(date, \\'yyyyMM\\') as int) as month\\n        , cast(concat(left(date,4),  right(datepart(ww, date) + 100, 2)) as int) as week\\n        , loads as impression_by_date\\n        , unique_viewers as users_by_date\\n        , name as activity_calendar_events\\n        , created_time as event_occurence_by_date\\n        , created_time as event_occurence_by_time\\n        , \\'Rishi Padda\\' as activity_implemented_by\\n        , likes as likes_consid_engage_by_date\\n        , plays as downloads_by_date\\n        , plays as total_engagements\\n        , case when loads = 0 or loads is null then 0 else (plays / loads) end as engagement_rate_by_activity_1\\n        , case when unique_viewers = 0 or unique_viewers is null then 0 else (plays / unique_viewers) end as engagement_rate_by_activity_2\\n        , mean_percent as conversion_listened_watched\\n        , finishes as listened_watched_full_podcast_episode\\n        , case when loads = 0 or loads is null then 0 else (plays / loads) end as video_view_rate\\n        , case when plays = 0 or plays is null then 0 else (finishes / plays) end as video_completion_rate\\n    from Raw_Vimeo','drop table if exists Temp_Raw_Vimeo'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          plays,",
						"          loads,",
						"          downloads,",
						"          finishes,",
						"          likes,",
						"          comments,",
						"          uri,",
						"          name,",
						"          created_time,",
						"          sizes,",
						"          unique_viewers,",
						"          mean_percent,",
						"          sum_seconds,",
						"          mean_seconds,",
						"          unique_loads",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Absorb')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Script1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "Absorb_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "Absorb_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					},
					{
						"name": "Script1",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "drop table if exists Temp_Raw_Absorb"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Absorb"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Acast_Downloads')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1_copy1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "ACastDownloads_DataFlow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"SourceProcessFiles": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 16,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "ACast"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Acast_ListenersPerEpisode')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Script2",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ACastListenersPerEpisode_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "ACastListenersPerEpisode",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"source1": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Coarse"
									}
								}
							]
						}
					},
					{
						"name": "Script1",
						"type": "Script",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "drop table if exists Temp_Raw_ACastListenersPerEpisode"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Script2",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "Script1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "CREATE TABLE Temp_Raw_ACastListenersPerEpisode(\n\tdate date NULL\n\t, listeners int NULL\n\t, episode_name nvarchar(200) NULL\n);"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Script3",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "ForEach1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "with final_table as (\n  select\n      a.date\n      , a.listeners\n      , replace(replace(substring(a.episode_name, 2, 128), '%20', ' '), '.csv', '') as episode_name\n  from Temp_Raw_ACastListenersPerEpisode a\n)\n-- select * from final_table\nMERGE INTO Raw_ACastListenersPerEpisode a\nUSING final_table b\n    ON a.date = b.date \n    and a.episode_name = b.episode_name\nWHEN MATCHED THEN\n  UPDATE SET \n        a.listeners  = b.listeners \nWHEN NOT MATCHED THEN\n  INSERT (date, listeners, episode_name)\n  VALUES (\n        b.date\n        , b.listeners\n        , b.episode_name \n        );"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Script4",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "Script3",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "with final_table as (\n    select\n        'Podcast/Vodcast' as channel\n        ,'Acast' as sub_channel\n        , date \n        , date as timestamp\n        , cast(format(date, 'yyyyMM') as int) as month\n        , cast(concat(left(date,4),  right(datepart(ww, date) + 100, 2)) as int) as week\n        , listeners as impression_by_date\n        , listeners as users_by_date\n        , episode_name as activity_calendar_events    --using listerners here until more clarity\n        , date as event_occurence_by_date    --using listerners here until more clarity \n        , date as event_occurence_by_time    --using listerners here until more clarity\n        , 'Russell Gower' as activity_implemented_by\n    from Raw_ACastListenersPerEpisode\n)\n\nMERGE INTO Changemakers_Combined_Overview a\nUSING final_table b\n    on a.channel = b.channel\n    and a.sub_channel = b.sub_channel\n    and a.date = b.date\n    and a.activity_calendar_events = b.activity_calendar_events \nWHEN MATCHED THEN\n  UPDATE SET \n        a.impression_by_date = b.impression_by_date\n        , a.users_by_date = b.users_by_date\n        , a.activity_calendar_events = b.activity_calendar_events\n        , a.event_occurence_by_date = b.event_occurence_by_date\n        , a.event_occurence_by_time = b.event_occurence_by_time\n        , a.activity_implemented_by = b.activity_implemented_by\nWHEN NOT MATCHED THEN\n  INSERT (channel, sub_channel, date, timestamp, month, week, impression_by_date, users_by_date, activity_calendar_events, event_occurence_by_date, event_occurence_by_time, activity_implemented_by)\n  VALUES (\n        b.channel\n        , b.sub_channel\n        , b.date \n        , b.timestamp\n        , b.month\n        , b.week\n        , b.impression_by_date\n        , b.users_by_date\n        , b.activity_calendar_events\n        , b.event_occurence_by_date\n        , b.event_occurence_by_time\n        , b.activity_implemented_by\n        );"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					},
					{
						"name": "Script5",
						"type": "Script",
						"dependsOn": [
							{
								"activity": "Script4",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabase_Changemakers",
							"type": "LinkedServiceReference"
						},
						"typeProperties": {
							"scripts": [
								{
									"type": "Query",
									"text": "drop table if exists Temp_Raw_ACastListenersPerEpisode"
								}
							],
							"scriptBlockExecutionTimeout": "02:00:00"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"episodeName": {
						"type": "String"
					}
				},
				"folder": {
					"name": "ACast"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/GoogleAnalytics_Engagment_Overview')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "GA_Engagement_Overview_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"modifiedDatetimeStart": {
									"value": "@addDays(utcNow(), -20)",
									"type": "Expression"
								},
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "GA_Engagement_Overview_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "GoogleAnalytics"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/GA_Engagement_Overview_DataFlow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/GoogleAnalytics_Snapshot')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "GA_Snapshot_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"modifiedDatetimeStart": {
									"value": "@addDays(utcNow(), -20)",
									"type": "Expression"
								},
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "GA_Snapshot_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "GoogleAnalytics"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/GA_Snapshot_DataFlow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Linkedin_Organic_ContentAllPosts')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "LinkedinContentAllPosts_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "LinkedinContentAllPosts_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Linkedin"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/LinkedinContentAllPosts_DataFlow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Linkedin_Organic_ContentMetrics')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "LinkedinContentMetrics_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "LinkedinContentMetrics_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Linkedin"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/LinkedinContentMetrics_DataFlow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Linkedin_Organic_Followers')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "LinkedinFollowers_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "LinkedinFollowers_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Linkedin"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/LinkedinFollowers_DataFlow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Linkedin_Organic_Visitors')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"description": "",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "des",
								"value": "dsad"
							}
						],
						"typeProperties": {
							"dataset": {
								"referenceName": "LinkedinVisitors_GetFiles",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childItems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "LinkedinVisitors_DataFlow",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"SourceProcessFiles": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 16,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"folder": {
					"name": "Linkedin"
				},
				"annotations": [],
				"lastPublishTime": "2023-10-23T11:09:52Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/LinkedinVisitors_DataFlow')]"
			]
		}
	]
}